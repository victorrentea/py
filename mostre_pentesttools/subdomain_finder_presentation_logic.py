# For Victor: this tool (SubdomainScanner) tries to find all the subdomains for a given target domain. 
# For example, given `google.com` as an input, it should return results like: `maps.google.com`, `mail.google.com`,
# `account.google.com`, etc. To do this it uses several discovery methods omitted here for brevity. What we have shown
# here is the current presentation layer: how a subdomain is sent to the UI after it is found.
# Additionally, an user might want some extra metadata about a subdomain: 
# - what is the WhoIs information associated with it?
# - does it host a web server on common ports (80, 443, 8080, 8443)? If so, show the user the <title> tag for it.

class SubdomainScanner(DiscoveryScanner):
    """Subdomain scanner implemented as a Discovery Scanner"""

    def __init__(
        self, domain, whois_info, web_details, unresolved_results, wordlist_file, max_number_of_results, methods
    ):
        self.tool_name = "Subdomain Scanner"
        self.domain: str = domain
        self.whois_info: bool = whois_info
        self.web_details: bool = web_details
        self.wordlist_file: str = wordlist_file
        self.unresolved_results: bool = unresolved_results # For Victor: should we show results that don't resolve to an IP?
        self.methods: list["str"] = methods
        self.max_number_of_results: int = max_number_of_results
        self.progress = 0
        self.grpc_channel = None

        DiscoveryScanner.__init__(self)

    def run(self):
        """This method implements a test performed within a scan
        Each scan can have multiple tests
        """
        # Obtain a new test object - it contains all info about this test
        test_obj = self.start_test(f"Starting {self.tool_name}...")

        # Connect to the subdomain finder gRPC historical service
        grpc_stub, self.grpc_channel = connect_to_grpc_subdomain_finder_historical_server(
            port=GRPC_PORT, tls_cred_path=GRPC_TLS_CREDS_PATH, server_hostname=GRPC_HOSTNAME
        )

        # Initialize subdomains_found outside of the try-except to avoid errors when inserting result in gRPC
        subdomains_found = set()

        # Do the testing work
        try:
            progress_unit = int(
                100 / (len(self.methods) + 1)
            )  # increment progress by this much every time a method finishes
            self.progress = 1
            # If the HTML search method is enabled, we want to store the URLs and do the extraction later.
            # Additionally, to avoid doing the same HTTP request in the fingerprinting phase,
            #   we also store the response associated with each URL.
            links_and_responses = {} if "website_search" in self.methods else None

            self.set_headers(test_obj)
            subdomains_found |= self.add_results(
                subdomains_found, {Subdomain(name=self.domain)}, test_obj, links_and_responses
            )

            ... 
            # Call all the discovery methods selected by the user
            for method in self.get_selected_discovery_methods():
                if (
                    len([subdomain.ip for subdomain in subdomains_found]) >= self.max_number_of_results
                ):  # Stop scan if we already reached the max number of results.
                    logging.debug("Scan stopping because max_number_of_results was reached")
                    break
                test_obj.test_description = f"Extracting subdomains from {method.display_name}..."
                logging.debug(f"Extracting subdomains from {method.display_name}...")
                current_results = set()
                try:
                    current_results = method.discover(
                        subdomains_already_found=subdomains_found, links_and_responses=links_and_responses
                    )
                except Exception:
                    logging.exception("Exception occured while running %s discovery method", method.display_name)
                test_obj.test_description = f"Getting subdomain details ({method.display_name})..."
                subdomains_found |= self.add_results(subdomains_found, current_results, test_obj, links_and_responses)
                # Update scan progress
                self.progress += progress_unit

            # Sort by ip (second column) - WARNING: if we ever change the index of the ip column,
            # we have to update the following line.
            # Added 'Did not resolve' support to final sorting.
            test_obj.output_data = sort_output(test_obj.output_data)

        except Exception:
            logging.exception(
                "find subdomains exception while running discovery methods in testfunc__docscan on %s", self.domain
            )

        finally:
            # If we have more results then MAX_NUMBER_OF_RESULTS we slice them
            #  in order to prevent MySQL errors
            if len(test_obj.output_data) > self.max_number_of_results:
                test_obj.output_data = sort_output_for_trunc(test_obj.output_data)
                slice_results(test_obj, self.max_number_of_results, self.add_info_text)

            # Insert results in the gRPC historical service (even if "passive_detection" method is not selected)
            if self.grpc_channel and subdomains_found:
                send_subdomains_as_messages_to_grpc(
                    stub=grpc_stub, subdomains_as_messages=parse_subdomains_to_subdomains_messages(subdomains_found)
                )

            # Close the channel if it exists
            if self.grpc_channel:
                self.grpc_channel.close()

            test_obj.set_caption(f"Found {len(test_obj.output_data)} subdomains")
            # Always finish the test
            logging.debug(
                "Raw data: %s\nHeaders: %s\nOutput_data: %s\n",
                str(test_obj.raw_output),
                str(test_obj.headers),
                str(test_obj.output_data),
            )
            self.finish_test(test_obj)

    def add_results(
        self,
        old_results: set["Subdomain"],
        new_results: set["Subdomain"],
        test_obj: DiscoveryTest,
        links_and_responses: dict = None,
    ) -> set["Subdomain"]:
        """
        Compares new_results with old_results and keeps only the trully new ones. (ones that are not in old_results)
        Then it resolves and finds the open ports for the ones without an IP already assigned.
        For each of them it saves their link and open_ports in its Subdomain instance.
        Next, it adds all new results to the user UI using test_obj.
        Finally, it returns the "trully new" results to be saved and used in other methods.
            with their open_ports, links and IPs assigned.
        """
        if len(old_results) >= self.max_number_of_results:
            return set()
        if not new_results:
            return set()

        test_description = test_obj.test_description
        distinct_results = new_results - old_results

        # If we do not have new results we return
        if not distinct_results:
            return set()

        distinct_results_hostnames = set()
        results_checked = set()
        # If web_details is True, we can not forget to check again already resolved subdomains
        #   because their pageTitle and Server will not be present anymore.
        # If web_details is False, we can go with a slighty faster scan that
        #   does not resolve domains that are already resolved
        if not self.web_details:
            # Set of subdomain hostnames, which are not already rezolved (ip == '').
            distinct_results_hostnames = set(subdomain.name for subdomain in distinct_results if subdomain.ip == "")
            # Set of already resolved subdomains (ip != '')
            results_checked = set(subdomain for subdomain in distinct_results if subdomain.ip != "")
        else:
            # Set of subdomain hostnames
            distinct_results_hostnames = set(subdomain.name for subdomain in distinct_results)

        # We create an interemediary result set which contains all new found subdoms
        # Results that we do not know if they resolve or not will have
        #   "Checking..." as their IP
        intermediary_results = set()
        intermediary_results |= results_checked
        intermediary_results |= old_results
        for subdomain in distinct_results_hostnames:
            if subdomain not in intermediary_results:
                intermediary_results.add(Subdomain(name=subdomain, ip="", checked=False))
        test_obj.output_data.clear()
        for subdomain in intermediary_results:
            self.print_row(subdomain, test_obj)
        test_obj.set_caption(f"Found {len(test_obj.output_data)} subdomains")
        port_associations = None
        ips_to_hosts: dict[str, str] = {}
        ports = "80,8080,443,8443"
        if distinct_results_hostnames or results_checked:
            ips: list[str] = []
            # Resolve new unresolved results
            if distinct_results_hostnames:
                test_obj.test_description = test_description + f"   (resolving DNS for {len(distinct_results)} hosts)"
                logging.debug(f"Resolving hostnames {len(distinct_results)}")
                for batch in chunked(distinct_results_hostnames, self.max_number_of_results):
                    ips_returned, ips_to_hosts_returned, _ = DnsResolver.resolve_dns(batch)
                    ips += ips_returned
                    ips_to_hosts = {
                        key: ips_to_hosts_returned.get(key, []) + ips_to_hosts.get(key, [])
                        for key in set(ips_to_hosts_returned) | set(ips_to_hosts)
                    }
                    hosts = set()
                    for host_list in ips_to_hosts.values():
                        hosts.update(host_list)
                    if len(hosts) >= self.max_number_of_results:
                        logging.debug("Stop resolving because max number of results was reached")
                        break
            # Add already resolved ips to the mix
            ips.extend({subdomain.ip for subdomain in results_checked} - set(ips))
            # Run nmap to detect their open ports
            if ips:
                test_obj.test_description = test_description + f"   (searching for open ports on {len(ips)} hosts)"
                # TODO: replace this two lines with a single scan_ports_multihost call
                # and adapt the code accordingly
                tree = UtilsNetwork.NmapScan.exec_nmap(set(ips), ports, False)
                port_associations = UtilsNetwork.NmapParser.parse_scan_results(tree)
        crt_result = 0

        subdomains = []
        num_results = 0
        if self.whois_info:
            whois_infos = self.resolve_dns(ips_to_hosts, results_checked)
            num_results = len(port_associations.hosts) if port_associations else 0
            for whois_info in whois_infos:
                whois_info.subdomains = set_open_ports_to_subdomains(port_associations, whois_info.subdomains)
                for subdomain in whois_info.subdomains:
                    subdomain.whois_data = (whois_info.netname, whois_info.country)
                    subdomains.append(subdomain)

        else:
            subdomains = self.resolve_dns(ips_to_hosts, results_checked)
            subdomains = set_open_ports_to_subdomains(port_associations, subdomains)
            num_results = len(subdomains)

        subdomains = get_links_for_subdomains(subdomains, port_associations, links_and_responses)

        if self.web_details and subdomains:
            test_obj.test_description = f"Getting Web Technologies for {len(subdomains)} subdomains"
            subdomains = get_web_info_for_subdomains(subdomains, links_and_responses)

        for subdomain in subdomains:
            crt_result += 1
            test_obj.test_description = test_description + f" ({crt_result}/{num_results})"

            # For each new resolved result we need to pop the older one
            #  from the output, the one which appeared as
            #  'Did not attempt to resolve yet' to avoid duplicates.
            test_obj.output_data = [row for row in test_obj.output_data if row[0] != subdomain.name]

            self.print_row(subdomain, test_obj)

            # also update the caption every 10 results when showing web details
            if crt_result % 10 == 0 and self.web_details:
                test_obj.output_data = sort_output(test_obj.output_data)
                test_obj.set_caption(f"Found {len(test_obj.output_data)} subdomains")

        # At the end of an add we need to take out all remaining
        # 'Checking...' results.
        #  They may be present only if self.unresolved_results == False
        output_has_unresolved_subdomains = True
        while output_has_unresolved_subdomains:
            output_has_unresolved_subdomains = False
            for index, row in enumerate(test_obj.output_data):
                if row[1] == "Checking...":
                    test_obj.output_data.pop(index)
                    output_has_unresolved_subdomains = True
                    break

        # Set the initial test description and update the caption to show the number of results
        test_obj.test_description = test_description
        test_obj.set_caption(f"Found {len(test_obj.output_data)} subdomains")

        return set(subdomains)

class TaskBase(object):
    """TaskBase is the base class for any scanner. It ensures various services such as:
    - communication with the Redis database (output update, stop)
    - container for test objects
    - returning the scan results in JSON format
    - self timeout"""

    def __init__(self, scan_type):
        self.tests = []
        self.task_status = TaskStatus.STARTED
        self.scan_type = scan_type  # discovery or vulnerability
        self.standalone = False
        self.start_time = time.localtime()
        self.end_time = time.localtime()
        self.disclaimer = ""
        self.task_id = None
        self.task_key = None
        self.do_run = True
        self.progress = 0
        self.wait = False
        self.stop_reason = None
        self.communicator_thread = None
        self._stats = {}  # dictionary for showing statistics after the scan has finished
        self.info_text: str = ""  # alerts displayed in the beginning of the scan only in platform report

        self.redis = None
        self.selenium_interface = None
        self.vpn_connection = None
        self.is_vpn = False
        self.max_scan_time = None

        try:
            sentry.setup()  # monitor exceptions
        except Exception:
            logging.exception("Failed to setup sentry")

        # This contains a list of items to be shown in the web interface
        # to show what is the scanner doing in real time
        self.scan_activity = ScanActivity()

        # Obtain the child class that was derived from TaskBase so
        # we can automatically find how many tests it has implemented
        if self.scan_type == "discovery":
            cls_obj = TaskBase.__subclasses__()[0].__subclasses__()[0]
        elif self.scan_type == "vulnerability":
            cls_obj = TaskBase.__subclasses__()[1].__subclasses__()[0]
        else:
            raise NotImplementedError()
        self.num_tests = get_num_tests(cls_obj)

        # Disable urllib3's InsecurePlatformWarning: A true SSLContext object is not available.
        # This can also be done by running the command: pip install requests[security]
        urllib3.disable_warnings()

class DiscoveryScanner(TaskBase):
    """Scanner class used for discovery type scanner. Ex: subdomain finder"""

    def __init__(self):
        TaskBase.__init__(self, "discovery")

    def start_test(self, test_description, test_name="default"):
        scan_test = DiscoveryTest(
            test_description, len(self.tests), test_name
        )  # The discovery scanner usually has only 1 test
        self.tests.append(scan_test)
        return scan_test

    def run(self):
        raise NotImplementedError()

class BaseTest:
    """This is the base class for any test performed within a scan."""

    def __init__(self, description: str, test_id: int, test_name: str = "default"):
        self.test_id: int = test_id
        self.test_description: str = description  # This is the description of the test currently performed
        self.test_name: str = test_name
        self.finished: bool = False
        self.vuln_id: str = "NONVULN-00-0000000"
        self.screenshots: Optional[list] = None  # This is a list of screenshots/None if not supported
        self.confirmed: bool = False  # The confirmed field means the scanner has almost 100% confidence on a finding.

    def dict_output(self):
        """Return the class attributes as dict."""
        return {
            "test_id": self.test_id,
            "test_description": self.test_description,
            "test_name": self.test_name,
            "test_finished": self.finished,
            "vuln_id": self.vuln_id,
            "screenshots": self.screenshots,
            "confirmed": self.confirmed,
        }

    def set_description(self, description: str):
        """Update the test_description attribute."""
        self.test_description = description

    def add_screenshot(self, base64_image: Optional[str], port: Optional[Union[int, str]] = None, caption: str = ""):
        """Add a screenshot to the list of screenshots of the test."""
        new_image = {
            "base64": base64_image,
            "caption": caption,
        }
        if port is not None:
            try:
                new_image["port"] = int(port)  # type: ignore
            except (ValueError, TypeError):
                logging.exception("Exception while adding port to screenshot")

        if self.screenshots is None:
            self.screenshots = []

        self.screenshots.append(new_image)

    @property
    def nr_screenshots(self):
        """Get the number of screenshots in this test."""
        return 0 if self.screenshots is None else len(self.screenshots)

class DiscoveryTest(BaseTest):
    """
    This class maintains information about the (single) test performed by a discovery scanner.
    It outputs a table with the discovered data or an error message.
    """

    def __init__(self, description: str, test_id: int = 0, test_name: str = "default"):
        self.raw_output = ""  # This is the raw output returned by the scanning tool
        self.output_data: list = []  # This is the structured data returned by the tool
        self.headers: list = []  # Title for each of the columns in the output data
        self.caption: str = ""  # Caption to display above table
        super().__init__(description, test_id, test_name)

    def set_headers(self, headers: list):
        """Update the headers attribute."""
        self.headers = headers

    def set_headers2(self, headers: list):
        """
        Set headers for new format of discovery tools.
        usage: set_headers2([('<name_in_json>', '<name_to_display>'), ..])
        example: set_headers2([('name', 'Name'), ('size', 'Page Size (KB)'), ('actions', '[[Actions]]'])
        """

        for elem in headers:
            self.headers.append({"item_name": elem[0], "display": elem[1]})

    def add_data_row(self, data_row: list):
        """Add a new data_row to the output_data attribute."""
        self.output_data.append(data_row)

    def set_caption(self, caption: str):
        """Update the caption attribute."""
        self.caption = caption

    def set_error(self, err_msg: str):
        """
        Use the test to display an error.
        The header will be "Error" and the output_data will be the given err_msg.
        """
        self.headers = ["Error"]
        self.output_data = [[err_msg]]

    def dict_output(self):
        """Return the class attributes as dict, including the base class attributes."""
        base_output = super().dict_output()
        base_output.update(
            {
                "raw_output": self.raw_output,
                "headers": self.headers,
                "caption": self.caption,
                "output_data": self.output_data,
            }
        )
        return base_output

class Subdomain:
    """
    We use this class to store information regarding each subdomain such as:
        - ip (string) = The IP of the Subdomain
        - checked (bool) = Whether the Subdomains resolves and is already resolved
        - open_ports (set[int]) = The open ports found by utils.scan_ports_multihost in add_results
        - name (string) = hostname of subdomain
        - link (string) = the link that points to the subdomain
        - whois_data (touple(netname : string, country : string))
                    = whois data of the subdomain (if checked)
        - web_info (touple(os : string, server : string, tech : string, platform : string, app_title : string))
                    = web info of the subdomain (if checked)
    """

    def __init__(self, name, ip="", checked=False):
        self.name = name
        self.ip = ip
        self.open_ports = set()
        self.checked = checked
        self.link = ""
        self.whois_data = ("", "")
        self.web_info = ("", "", "", "", "")
        if self.ip != "":
            self.checked = True

def set_open_ports_to_subdomains(
    port_association: UtilsNetwork.NmapResults, subdomains: list[Subdomain]
) -> list[Subdomain]:
    """
    Saves found open ports into their corresponding subdomain instance.

    Args:
        port_association (UtilsNetwork.NmapResults): result of scan_ports_multihosts, which
            contains "open_ports" as one of its field
        subdomains (list[Subdomain]): list of instances of Subdomain class

    Returns:
        subdomains (list[Subdomain]): list of instances of Subdomain class
    """
    if not port_association:
        return subdomains
    for subdomain in subdomains:
        host_data = None
        for host in port_association.hosts:
            if host.ip_address == subdomain.ip:
                host_data = host
                break
        if not host_data:
            continue
        for port in [port for port in host_data.ports if port.port_state == "open"]:
            subdomain.open_ports.add(port.port_number)

    return subdomains

def get_web_info_for_subdomains(
    subdomains: list["Subdomain"], links_and_responses: dict[str, requests.Response], num_threads=20
) -> set["Subdomain"]:
    """
    Gets a list of Subdomain instances and returns the same list,
        but with the field 'web_info' assigned where it can be assigned.

    Args:
        subdomain (list[Subdomain]): Subdomain to fingerprint list
        num_threads (int): Default = 20. The number of threads for this method.

    Returns:
        (set[Subdomain]) with 'web_info' assigned

    """
    subdoms_to_search: Queue[Subdomain] = Queue()
    subdomains_results: set[Subdomain] = set()
    subdomains_without_link = set()
    threads = []

    for subdomain in subdomains:
        if subdomain.link != "":
            subdoms_to_search.put(subdomain)
        else:
            subdomains_without_link.add(subdomain)

    # If we do not have any subdomain with link (we can run fingerprint only on subdomains with links)
    #   we can return here
    if not subdoms_to_search:
        return subdomains_without_link

    logging.debug(
        "Started multithreading for Web Technologies with %i subdomains(%i with link)",
        len(subdomains),
        (len(subdomains) - len(subdomains_without_link)),
    )

    for _ in range(num_threads):
        thread = Thread(target=run_extract_web_info, args=(subdoms_to_search, subdomains_results, links_and_responses))
        thread.daemon = True
        thread.start()
        threads.append(thread)

    # Some threats finish after 3-4 seconds so we should get though all of them
    #   and make sure they are finished
    time.sleep(1)
    subdoms_to_search.join()
    for thread in threads:
        thread.join()

    for subdomain in subdomains_without_link:
        subdomains_results.add(subdomain)

    return subdomains_results

def get_link(
    subdomain: "Subdomain", port_associations: UtilsNetwork.NmapResults, links: dict[str, requests.Response]
) -> str:
    """
    Using the subdomain's ip matches the given subdomain with the open ports (if there are any for it)
        found in port_associations. It attaches the open port to the subdomain's hostname and returns it.

    Also if links is not None, it adds the found link to the links dictionary as a key,
        to be later used in website_search method.

    Args:
        subdomain (Subdomain): Subdomain instance
        port_associations (UtilsNetwork.NmapResults): nmap scan results
        links (dict[str, requests.Response]): previous found links as keys and their responses saved as entries

    Returns:
        (str): link to the given subdomain
    """
    sd_link = ""
    if port_associations is None:
        return ""

    host_data = None
    for host in port_associations.hosts:
        if host.ip_address == subdomain.ip:
            host_data = host
            break

    if not host_data:
        return ""

    open_ports = {port.port_number for port in host_data.ports if port.port_state == "open"}
    if open_ports.intersection({80, 8080}):
        sd_link = "http://" + subdomain.name
        if 80 not in open_ports:
            sd_link += ":8080"
        if links is not None:
            links[sd_link] = None

    if open_ports.intersection({443, 8443}):
        sd_link = "https://" + subdomain.name
        if 443 not in open_ports:
            sd_link += ":8443"
        if links is not None:
            links[sd_link] = None

    return sd_link

def get_links_for_subdomains(
    subdomains: list["Subdomain"], port_associations: UtilsNetwork.NmapResults, links: list[str]
) -> list["Subdomain"]:
    """Using port_associations, it tries to get the link for each
        subdomain received from the list of instances of Subdomain.

    Args:
        subdomains : list of subdomains for which to assign links.
        port_associations : UtilsNetwork.NmapResults result from scan_ports_multihosts (nmap)
        links : list of strings (saved for method website_search)

    Returns:
        list of Subdomain : same subdomain instances but with .link assigned
    """
    for subdomain in subdomains:
        subdomain.link = get_link(subdomain, port_associations, links)
    return subdomains

